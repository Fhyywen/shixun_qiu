#!/usr/bin/env python3
"""
æ£€æŸ¥æ¨¡å‹è·¯å¾„çš„ç‹¬ç«‹è„šæœ¬
"""

import os
import torch
from sentence_transformers import SentenceTransformer
from config import Config


def check_model_paths():
    print("=" * 60)
    print("ğŸ” æ¨¡å‹è·¯å¾„æ£€æŸ¥å·¥å…·")
    print("=" * 60)

    # è·å–é…ç½®
    config = Config()
    model_name = config.EMBEDDING_MODEL

    print(f"ğŸ“‹ é…ç½®çš„æ¨¡å‹: {model_name}")
    print(f"ğŸ“ Torch ç¼“å­˜è·¯å¾„: {torch.hub.get_dir()}")
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\nğŸŒ ç¯å¢ƒå˜é‡:")
    for var in ['TRANSFORMERS_CACHE', 'SENTENCE_TRANSFORMERS_HOME', 'HF_HOME']:
        value = os.getenv(var)
        print(f"   {var}: {value if value else 'æœªè®¾ç½®'}")

    # å°è¯•åŠ è½½æ¨¡å‹æ¥å‘ç°è·¯å¾„
    print(f"\nğŸš€ å°è¯•åŠ è½½æ¨¡å‹: {model_name}")
    try:
        model = SentenceTransformer(model_name)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“ æ¨¡å‹å­˜å‚¨è·¯å¾„: {model._model_path}")

        # æ£€æŸ¥æ–‡ä»¶
        if os.path.exists(model._model_path):
            print(f"\nğŸ“„ æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:")
            total_size = 0
            for file in os.listdir(model._model_path):
                file_path = os.path.join(model._model_path, file)
                size = os.path.getsize(file_path) / (1024 * 1024)
                total_size += size
                print(f"   - {file}: {size:.2f} MB")

            print(f"\nğŸ’¾ æ€»å¤§å°: {total_size:.2f} MB")
        else:
            print("âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨")

    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: æ¨¡å‹å°†è‡ªåŠ¨ä¸‹è½½åˆ°ä¸Šè¿°ç¼“å­˜è·¯å¾„")


if __name__ == "__main__":
    check_model_paths()